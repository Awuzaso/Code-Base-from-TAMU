{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(b) Classification: From data exploration, we can notice that the the outcome value (i.e. the\n",
    "burned area) is zero for many samples, meaning that the corresponding forests are not affected\n",
    "by fire. \n",
    "\n",
    "Therefore we can dichotomize the outcome variable, based on whether its corresponding\n",
    "value is zero or greater than zero. \n",
    "\n",
    "    This creates the following two classes:\n",
    "\n",
    "        Class 0: Forests not affected by the fire, i.e. area = 0\n",
    "\n",
    "        Class 1: Forests affected by the fire, i.e. area > 0\n",
    "\n",
    "        After dichotomizing the outcome variable, we can run a classification task to predict whether or\n",
    "        not fire will occur in a certain forest based on the input features.\n",
    "\n",
    "'''\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from numpy import genfromtxt\n",
    "import math\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Normalizing features.\n",
    "'''\n",
    "\n",
    "def normalizeData(inDF):\n",
    "    x = inDF[1:len(inDF)]\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    normalizedDF = pd.DataFrame(min_max_scaler.fit_transform(x))\n",
    "    return normalizedDF\n",
    "    \n",
    "trainData_x = pd.DataFrame(trainCSV[:,0][1:len(trainCSV)], columns=['x'])\n",
    "trainData_y = pd.DataFrame(trainCSV[:,1][1:len(trainCSV)], columns=['y'])\n",
    "trainData_month = pd.DataFrame(trainCSV[:,2][1:len(trainCSV)], columns=['month'])\n",
    "trainData_day = pd.DataFrame(trainCSV[:,3][1:len(trainCSV)], columns=['day'])\n",
    "trainData_ffmc = pd.DataFrame(trainCSV[:,4][1:len(trainCSV)], columns=['FFMC'])\n",
    "trainData_dmc = pd.DataFrame(trainCSV[:,5][1:len(trainCSV)], columns=['DMC'])\n",
    "trainData_dc = pd.DataFrame(trainCSV[:,6][1:len(trainCSV)], columns=['DC'])\n",
    "trainData_isi = pd.DataFrame(trainCSV[:,7][1:len(trainCSV)], columns=['ISI'])\n",
    "trainData_temp = pd.DataFrame(trainCSV[:,8][1:len(trainCSV)], columns=['temp'])\n",
    "trainData_rh = pd.DataFrame(trainCSV[:,9][1:len(trainCSV)], columns=['RH'])\n",
    "trainData_wind = pd.DataFrame(trainCSV[:,10][1:len(trainCSV)], columns=['wind'])\n",
    "trainData_rain = pd.DataFrame(trainCSV[:,11][1:len(trainCSV)], columns=['rain'])\n",
    "trainData_outcome = pd.DataFrame(trainCSV[:,12][1:len(trainCSV)], columns=['outcome'])\n",
    "\n",
    "\n",
    "normalTrainData = normalizeData(trainData_x)\n",
    "ny = normalizeData(trainData_y)\n",
    "nm = normalizeData(trainData_month)\n",
    "nd = normalizeData(trainData_day)\n",
    "n_ffmc = normalizeData(trainData_ffmc)\n",
    "n_dmc = normalizeData(trainData_dmc)\n",
    "n_dc = normalizeData(trainData_dc)\n",
    "n_isi = normalizeData(trainData_isi)\n",
    "n_temp = normalizeData(trainData_temp)\n",
    "n_rh = normalizeData(trainData_rh)\n",
    "n_wind = normalizeData(trainData_wind)\n",
    "n_rain = normalizeData(trainData_rain)\n",
    "\n",
    "\n",
    "normalTrainData['1']=ny\n",
    "normalTrainData['2']=nm\n",
    "normalTrainData['3']=nd\n",
    "normalTrainData['4']=n_ffmc\n",
    "normalTrainData['5']=n_dmc\n",
    "normalTrainData['6']=n_dc\n",
    "normalTrainData['7']=n_isi\n",
    "normalTrainData['8']=n_temp\n",
    "normalTrainData['9']=n_rh\n",
    "normalTrainData['10']=n_wind\n",
    "normalTrainData['11']=n_rain\n",
    "normalTrainData['outcome']=trainData_outcome\n",
    "normTrainData = normalTrainData.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData_x = pd.DataFrame(testCSV[:,0][1:len(testCSV)], columns=['x'])\n",
    "testData_y = pd.DataFrame(testCSV[:,1][1:len(testCSV)], columns=['y'])\n",
    "testData_month = pd.DataFrame(testCSV[:,2][1:len(testCSV)], columns=['month'])\n",
    "testData_day = pd.DataFrame(testCSV[:,3][1:len(testCSV)], columns=['day'])\n",
    "testData_ffmc = pd.DataFrame(testCSV[:,4][1:len(testCSV)], columns=['FFMC'])\n",
    "testData_dmc = pd.DataFrame(testCSV[:,5][1:len(testCSV)], columns=['DMC'])\n",
    "testData_dc = pd.DataFrame(testCSV[:,6][1:len(testCSV)], columns=['DC'])\n",
    "testData_isi = pd.DataFrame(testCSV[:,7][1:len(testCSV)], columns=['ISI'])\n",
    "testData_temp = pd.DataFrame(testCSV[:,8][1:len(testCSV)], columns=['temp'])\n",
    "testData_rh = pd.DataFrame(testCSV[:,9][1:len(testCSV)], columns=['RH'])\n",
    "testData_wind = pd.DataFrame(testCSV[:,10][1:len(testCSV)], columns=['wind'])\n",
    "testData_rain = pd.DataFrame(testCSV[:,11][1:len(testCSV)], columns=['rain'])\n",
    "testData_outcome = pd.DataFrame(testCSV[:,12][1:len(testCSV)], columns=['outcome'])\n",
    "\n",
    "\n",
    "normalTestData = normalizeData(testData_x)\n",
    "nt_y = normalizeData(testData_y)\n",
    "nt_m = normalizeData(testData_month)\n",
    "nt_d = normalizeData(testData_day)\n",
    "nt_ffmc = normalizeData(testData_ffmc)\n",
    "nt_dmc = normalizeData(testData_dmc)\n",
    "nt_dc = normalizeData(testData_dc)\n",
    "nt_isi = normalizeData(testData_isi)\n",
    "nt_temp = normalizeData(testData_temp)\n",
    "nt_rh = normalizeData(testData_rh)\n",
    "nt_wind = normalizeData(testData_wind)\n",
    "nt_rain = normalizeData(testData_rain)\n",
    "\n",
    "\n",
    "normalTestData['1']=nt_y\n",
    "normalTestData['2']=nt_m\n",
    "normalTestData['3']=nt_d\n",
    "normalTestData['4']=nt_ffmc\n",
    "normalTestData['5']=nt_dmc\n",
    "normalTestData['6']=nt_dc\n",
    "normalTestData['7']=nt_isi\n",
    "normalTestData['8']=nt_temp\n",
    "normalTestData['9']=nt_rh\n",
    "normalTestData['10']=nt_wind\n",
    "normalTestData['11']=nt_rain\n",
    "normalTestData['outcome']=testData_outcome\n",
    "normTestData = normalTestData.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-effe53ab973e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtestCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrainCSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0mfhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/lib/_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             return _file_openers[ext](found, mode=mode,\n\u001b[0;32m--> 616\u001b[0;31m                                       encoding=encoding, newline=newline)\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../test.csv'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(b.i) (1 point) Implement a K-Nearest Neighbor classifier (K-NN) using the euclidean distance\n",
    "as a distance measure to perform the above binary classification task. Reminder: Donâ€™t forget\n",
    "to normalize the features.\n",
    "'''\n",
    "\n",
    "\n",
    "testCSV = genfromtxt('/Users/awuzaso/Downloads/test.csv', delimiter=',')\n",
    "trainCSV = genfromtxt('/Users/awuzaso/Downloads/train.csv', delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DICHOTOMIZE\n",
    "trainCSV_nb = []\n",
    "trainCSV_b = []\n",
    "\n",
    "def splitCSVData(csvData):\n",
    "    nbData = []\n",
    "    bData = []\n",
    "    for i in range (1, len(csvData)):\n",
    "        if(csvData[:,12][i] == 0):\n",
    "            nbData.append(csvData[i])\n",
    "        else:\n",
    "            bData.append(csvData[i])\n",
    "    return nbData,bData\n",
    "\n",
    "def euclideanDistance(testDataSample,trainDataSample,feature_1,feature_2):\n",
    "    distance_x = pow((testDataSample[feature_1]-trainDataSample[feature_1]),2)\n",
    "    distance_y = pow((testDataSample[feature_2]-trainDataSample[feature_2]),2)\n",
    "    distance = math.sqrt(distance_x + distance_y)\n",
    "    return distance\n",
    "\n",
    "def evalClassification(testSample, classification,index):\n",
    "    if(testSample[index] == classification[index]):\n",
    "        #print(\"Classification is correct.\")\n",
    "        return 1\n",
    "    else:\n",
    "        #print(\"Classification is incorrect.\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def gatherVotes(testSample,class_1,class_2,feature_1,feature_2,in_kNeighbors):\n",
    "    vote_class_1 = []\n",
    "    vote_class_2 = []\n",
    "    \n",
    "    for class_1_sample in class_1:\n",
    "        class_1_distance = euclideanDistance(testSample,class_1_sample,feature_1,feature_2)\n",
    "        vote_class_1.append(class_1_distance)\n",
    "        \n",
    "    for class_2_sample in class_2:\n",
    "        class_2_distance = euclideanDistance(testSample,class_2_sample,feature_1,feature_2)\n",
    "        vote_class_2.append(class_2_distance)   \n",
    "\n",
    "    class_1_w_votes = np.column_stack((class_1,vote_class_1))\n",
    "    class_2_w_votes = np.column_stack((class_2,vote_class_2))\n",
    "    \n",
    "    classTogether = np.vstack ((class_1_w_votes, class_2_w_votes) )\n",
    "    classTogether_sort = classTogether[classTogether[:,13].argsort()]\n",
    "    flipsort_class = np.flip(classTogether_sort,0)\n",
    "    \n",
    "    \n",
    "    #np.savetxt(\"/Users/awuzaso/Downloads/sortedClassVotes.csv\", flipsort, delimiter=\",\")\n",
    "    iterVal = 0\n",
    "    k_value = in_kNeighbors\n",
    "    voteForClass_I = 0\n",
    "    voteForClass_II = 0\n",
    "    classifiedCorrectly = 0\n",
    "    \n",
    "    while iterVal < k_value:\n",
    "        if flipsort_class[iterVal][12] == 0:\n",
    "            voteForClass_I = voteForClass_I + 1\n",
    "        else:\n",
    "            voteForClass_II = voteForClass_II + 1\n",
    "        iterVal = iterVal+1\n",
    "        \n",
    "    if (voteForClass_I > voteForClass_II):\n",
    "        '''\n",
    "        print(\"Burned area value: %s\" % (testSample[12]))\n",
    "        print(\"Class I is the vote.\")\n",
    "        print(\"Votes for class I: %s \" %(voteForClass_I))\n",
    "        print(\"Votes for class II: %s \"% (voteForClass_II))\n",
    "        '''\n",
    "        classifiedCorrectly = evalClassification(testSample,class_1[0],12)\n",
    "        \n",
    "        \n",
    "    elif (voteForClass_I < voteForClass_II):\n",
    "        '''\n",
    "        print(\"Burned area value:  %s\" % (testSample[12]))\n",
    "        print(\"Class II is the vote.\")\n",
    "        print(\"Votes for class I: %s \" %(voteForClass_I))\n",
    "        print(\"Votes for class II: %s \"% (voteForClass_II))\n",
    "        '''\n",
    "        classifiedCorrectly = evalClassification(testSample,class_2[0],12)\n",
    "    else:\n",
    "        '''\n",
    "        print(\"Burned area value:  %s\" % (testSample[12]))\n",
    "        print(\"No class can be decided.\")\n",
    "        print(\"Votes for class I: %s \" %(voteForClass_I))\n",
    "        print(\"Votes for class II: %s \"% (voteForClass_II))\n",
    "        '''\n",
    "    return classifiedCorrectly\n",
    "\n",
    "#trainCSV_nb,trainCSV_b = splitCSVData(normTrainData,trainCSV_nb,trainCSV_b)\n",
    "\n",
    "trainCSV_nb,trainCSV_b = splitCSVData(normTrainData)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feat_X = 0\n",
    "feat_Y = 1\n",
    "feat_month = 2\n",
    "feat_FFMC = 3\n",
    "feat_DMC = 4\n",
    "feat_DC = 5\n",
    "feat_ISI = 6\n",
    "feat_temp = 7\n",
    "feat_RH = 4\n",
    "feat_wind = 5\n",
    "feat_area = 6\n",
    "feat_rain = 7\n",
    "\n",
    "\n",
    "kNeighbors = 30\n",
    "\n",
    "def knnClassifier(testData,class_1,class_2,feat_1,feat_2,kNeighbors):\n",
    "    samplesCorrectlyIdentified = 0\n",
    "    for testDataSample in testData:\n",
    "        samplesCorrectlyIdentified += gatherVotes(testDataSample,class_1,class_2,feat_1,feat_2,kNeighbors)\n",
    "    classificationAccuracy = samplesCorrectlyIdentified/float(len(testData))*100\n",
    "    print(\"Classification accuracy: %s %%\" %(classificationAccuracy))\n",
    "    #print(\"Samples correctly identified: %s\" %(samplesCorrectlyIdentified))\n",
    "    #print(\"Total samples: %s\" %(len(testData)))\n",
    "    return classificationAccuracy\n",
    "\n",
    "knnClassifier(normTestData,trainCSV_nb,trainCSV_b,feat_X,feat_Y,kNeighbors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 neighbors\n",
      "Classification accuracy: 53.2608695652 %\n",
      "Classification accuracy: 13.0434782609 %\n",
      "Classification accuracy: 16.3043478261 %\n",
      "Classification accuracy: 36.9565217391 %\n",
      "Classification accuracy: 33.3333333333 %\n",
      "Average accuracy: 30.5797101449\n",
      "2 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 3.26086956522 %\n",
      "Classification accuracy: 16.3043478261 %\n",
      "Classification accuracy: 19.5652173913 %\n",
      "Classification accuracy: 25.8064516129 %\n",
      "Average accuracy: 12.9873772791\n",
      "3 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 26.0869565217 %\n",
      "Classification accuracy: 20.652173913 %\n",
      "Classification accuracy: 25.0 %\n",
      "Classification accuracy: 32.2580645161 %\n",
      "Average accuracy: 20.7994389902\n",
      "4 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 13.0434782609 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 21.5053763441 %\n",
      "Average accuracy: 11.2575970079\n",
      "5 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 6.52173913043 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 36.9565217391 %\n",
      "Classification accuracy: 39.7849462366 %\n",
      "Average accuracy: 19.4787283777\n",
      "6 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 1.08695652174 %\n",
      "Classification accuracy: 13.0434782609 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 8.60215053763 %\n",
      "Average accuracy: 7.37260402057\n",
      "7 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 1.08695652174 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 27.1739130435 %\n",
      "Classification accuracy: 35.4838709677 %\n",
      "Average accuracy: 15.5750350631\n",
      "8 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 1.08695652174 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 25.8064516129 %\n",
      "Average accuracy: 12.5525946704\n",
      "9 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 1.08695652174 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 23.9130434783 %\n",
      "Classification accuracy: 31.1827956989 %\n",
      "Average accuracy: 14.0626460963\n",
      "10 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 1.08695652174 %\n",
      "Classification accuracy: 13.0434782609 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 10.752688172 %\n",
      "Average accuracy: 9.32445067789\n",
      "11 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 16.1290322581 %\n",
      "Average accuracy: 11.2692847125\n",
      "12 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 16.1290322581 %\n",
      "Average accuracy: 11.2692847125\n",
      "13 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 25.0 %\n",
      "Classification accuracy: 17.2043010753 %\n",
      "Average accuracy: 12.136512389\n",
      "14 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 11.8279569892 %\n",
      "Average accuracy: 10.4090696587\n",
      "15 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 15.0537634409 %\n",
      "Average accuracy: 11.054230949\n",
      "16 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 21.7391304348 %\n",
      "Classification accuracy: 15.0537634409 %\n",
      "Average accuracy: 11.054230949\n",
      "17 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 16.3043478261 %\n",
      "Classification accuracy: 26.0869565217 %\n",
      "Classification accuracy: 15.0537634409 %\n",
      "Average accuracy: 12.3585787751\n",
      "18 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 4.34782608696 %\n",
      "Classification accuracy: 14.1304347826 %\n",
      "Classification accuracy: 25.0 %\n",
      "Classification accuracy: 13.9784946237 %\n",
      "Average accuracy: 11.4913510986\n",
      "19 neighbors\n",
      "Classification accuracy: 0.0 %\n",
      "Classification accuracy: 6.52173913043 %\n",
      "Classification accuracy: 16.3043478261 %\n",
      "Classification accuracy: 26.0869565217 %\n",
      "Classification accuracy: 15.0537634409 %\n",
      "Average accuracy: 12.7933613838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "'''\n",
    "(b.ii) (0.5 point) Explore different values of K through cross-validation on the training set.\n",
    "Plot the classification accuracy, i.e. (#samples correctly classified) / (total #samples), against\n",
    "the different values of K. Please implement cross-validation from scratch and do not\n",
    "use available libraries.\n",
    "'''\n",
    "dataSamplesCount = len(normTrainData)\n",
    "folds = 5\n",
    "samplesPerFold = dataSamplesCount/folds\n",
    "\n",
    "\n",
    "split_1_train_nb,split_1_train_b = splitCSVData( normTrainData[93:dataSamplesCount] )\n",
    "split_1_test = normTrainData[0:92]\n",
    "\n",
    "split_2_train_nb,split_2_train_b = splitCSVData( np.vstack([normTrainData[0:92],normTrainData[186:dataSamplesCount]]) )\n",
    "split_2_test = normTrainData[93:185]\n",
    "\n",
    "split_3_train_nb,split_3_train_b = splitCSVData( np.vstack([normTrainData[0:185],normTrainData[279:dataSamplesCount]]) )\n",
    "split_3_test = normTrainData[186:278]\n",
    "\n",
    "split_4_train_nb,split_4_train_b = splitCSVData( np.vstack([normTrainData[0:278],normTrainData[372:dataSamplesCount]]) )\n",
    "split_4_test = normTrainData[279:371]\n",
    "\n",
    "split_5_train_nb,split_5_train_b = splitCSVData( normTrainData[0:371] )\n",
    "split_5_test = normTrainData[372:dataSamplesCount]\n",
    "\n",
    "# TEST 1:\n",
    "kNeighbors = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crossValidationKNN(kNeighbors):\n",
    "    accuracies = 0.0\n",
    "    #print(\"Split I\")\n",
    "    accuracies += knnClassifier(split_1_test,split_1_train_nb,split_1_train_b,feat_X,feat_Y,kNeighbors)\n",
    "\n",
    "    #print(\"Split II\")\n",
    "    accuracies += knnClassifier(split_2_test,split_2_train_nb,split_2_train_b,feat_X,feat_Y,kNeighbors)\n",
    "\n",
    "    #print(\"Split III\")\n",
    "    accuracies += knnClassifier(split_3_test,split_3_train_nb,split_3_train_b,feat_X,feat_Y,kNeighbors)\n",
    "\n",
    "    #print(\"Split IV\")\n",
    "    accuracies += knnClassifier(split_4_test,split_4_train_nb,split_4_train_b,feat_X,feat_Y,kNeighbors)\n",
    "\n",
    "    #print(\"Split V\")\n",
    "    accuracies += knnClassifier(split_5_test,split_5_train_nb,split_5_train_b,feat_X,feat_Y,kNeighbors)\n",
    "\n",
    "    avgAccuracy = accuracies/5.0\n",
    "    print(\"Average accuracy: %s\" % (avgAccuracy))\n",
    "    return [kNeighbors,avgAccuracy]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kVals = []\n",
    "\n",
    "iterVal = 1\n",
    "while iterVal < 20:\n",
    "    print(\"%s neighbors\" % (iterVal))\n",
    "    kVals.append(crossValidationKNN(iterVal))\n",
    "    iterVal += 1\n",
    "\n",
    "    \n",
    "xRange = []  \n",
    "yRange = []  \n",
    "for i in kVals:\n",
    "    xRange.append(i[0])\n",
    "    yRange.append(i[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(xRange,yRange)\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 20.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnClassifier(normTestData,trainCSV_nb,trainCSV_b,feat_X,feat_Y,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
